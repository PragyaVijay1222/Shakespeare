{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "388d8813-7a18-48ac-8cc0-fbb0f7897df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9e46ac9-19c8-4559-9269-6ce1e6ef6351",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1729396c-f42b-44c7-8f0a-f40d13514286",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d55e1202-bf4b-4964-95f2-bb9becfa952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text[300000:800000]\n",
    "characters = sorted(set(text))\n",
    "char_to_index = dict((c,i) for i, c in enumerate(characters))\n",
    "index_to_char = dict((i,c) for i, c in enumerate(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "424ad544-acdf-42a5-978f-170cf6c7358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 40\n",
    "STEP_SIZE =3\n",
    "sentences = []\n",
    "next_characters = []\n",
    "\n",
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "    sentences.append(text[i : i+SEQ_LENGTH])\n",
    "    next_characters.append(text[i+SEQ_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33efb9e4-6e2e-4364-92d2-3a5b1984a4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=np.bool_)\n",
    "y = np.zeros((len(sentences), len(characters)), dtype=np.bool_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c00b8a8-d1a9-4a41-8bef-3c8e44c16d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "    for t, character in enumerate(sentence):\n",
    "        x[i, t, char_to_index[character]]=1\n",
    "    y[i, char_to_index[next_characters[i]]] = 1 \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b873dca1-e579-487d-b9f7-fa2ad9cc014d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LLM\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 95ms/step - loss: 2.5066\n",
      "Epoch 2/4\n",
      "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 94ms/step - loss: 1.7976\n",
      "Epoch 3/4\n",
      "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - loss: 1.6264\n",
      "Epoch 4/4\n",
      "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - loss: 1.5311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d1f2d05410>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
    "model.fit(x,y, batch_size= 256, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40d1ea89-6745-4fc8-b4d3-da40af2c772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('textgenerator.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "205b9161-d6e0-412b-a99d-a4f4c6508ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('textgenerator.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13e98df0-43b7-4c57-8464-84fcf13c1125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds=np.asarray(preds).astype('float64')\n",
    "    preds=np.log(preds)/temperature\n",
    "    exp_preds=np.exp(preds)\n",
    "    preds=exp_preds/np.sum(exp_preds)\n",
    "    probas=np.random.multinomial(1,preds,1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1dbeade-8c13-491e-ba3a-75afc0a6812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, temperature):\n",
    "    start_index=random.randint(0,len(text)-SEQ_LENGTH-1)\n",
    "    generated=''\n",
    "    sentence = text[start_index: start_index+SEQ_LENGTH]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "        x = np.zeros((1,SEQ_LENGTH, len(characters)))\n",
    "        for t, character in enumerate(sentence):\n",
    "            x[0,t,char_to_index[character]]=1\n",
    "            \n",
    "        predictions = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(predictions, temperature)\n",
    "        next_character = index_to_char[next_index]\n",
    "\n",
    "        generated += next_character\n",
    "        sentence = sentence[1:]+ next_character\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98d87abd-65d2-4fec-b209-cbc6a8ea13d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------0.2temp-----------\n",
      "ud steed's neck,\n",
      "bespake them thus: 'i took and the heads and his face of the sent\n",
      "to make the boling his fould my soul the father,\n",
      "and thou wilt heaven to my soul the comeseless all the fould,\n",
      "and and the fight to the cast the cannot to the comesel,\n",
      "and i am so the foul the fight to the faith,\n",
      "and with her forth of the sould his soul,\n",
      "an\n",
      "-----------0.4temp-----------\n",
      "atter.\n",
      "my conscience hath a thousand severe his foulds,\n",
      "and i revenge and heavens and here, and me.\n",
      "\n",
      "king henry vi:\n",
      "that have may heaven of the words and all them,\n",
      "and the suns to the faith and be to himself\n",
      "and the shall shall be i am the starms the crown,\n",
      "and the great my soul to the house of lament,\n",
      "and the sould my soul the wast the c\n",
      "-----------0.6temp-----------\n",
      "raight,\n",
      "for so he said he would: i hear the good\n",
      "is not conceit with the starbing foot, have his viclerine,\n",
      "with the lamis and in a doom, own morth!\n",
      "news i will my foul with so and to thy gloucester,\n",
      "and marry took to me to the shall of lies\n",
      "and have not the england, and have with hears sfall parchall,\n",
      "but fortune him with your lady your \n",
      "-----------0.8temp-----------\n",
      "lood,\n",
      "or seven fair branches springing footarings:\n",
      "then i have done envenient himset would me!\n",
      "my fortuned and till it ungrave this traitor,\n",
      "and with eyes that been piless his dends.\n",
      "\n",
      "capulet:\n",
      "we but to my himself to-mort pealle, to will,\n",
      "as heavy in the master sorright placcience\n",
      "and sunchour and opent his lord are tuend,\n",
      "and hearted of \n",
      "-----------1.0temp-----------\n",
      "e seen: my crown is called content:\n",
      "a crown of boy,  comese are his noileacited:\n",
      "i smeet to the friend kings: and, nor be before france to seem,\n",
      "duke in anthath tears?'\n",
      "would till the juliat to know thee with you sill,\n",
      "that seeth a lamed talk thou then done's talates,\n",
      "and not it parts, nigh house, too have unstite.\n",
      "hast no caaled unturge;\n"
     ]
    }
   ],
   "source": [
    "print('-----------0.2temp-----------')\n",
    "print(generate_text(300, 0.2))\n",
    "print('-----------0.4temp-----------')\n",
    "print(generate_text(300, 0.4))\n",
    "print('-----------0.6temp-----------')\n",
    "print(generate_text(300, 0.6))\n",
    "print('-----------0.8temp-----------')\n",
    "print(generate_text(300, 0.8))\n",
    "print('-----------1.0temp-----------')\n",
    "print(generate_text(300, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14960697-25cb-454e-be5b-5d82722641a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
